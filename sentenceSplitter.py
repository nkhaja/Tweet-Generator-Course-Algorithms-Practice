import refinedCorpus
import nltk
import codecs

# txt = "GoT.txt"
# txt_as_string = codecs.open(txt,encoding = 'utf-8')#open(filename)
# txt_as_string = txt_as_string.read()
# filteredText = txt_as_string.encode('ascii','ignore')

# sentence = ["""At eight o'clock on Thursday morning
# ... Arthur didn't feel very good."""]
# tokens = nltk.word_tokenize(sentence)
#
# index = 0
# for i in range(len(tokens)):
#     print tokens[i]
